{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Base Model\n",
    "\n",
    "Summary: Purpose of this notebook is to dive into the base model developed by vijay033 and whos code is found in the Git Repo https://github.com/vijay033/Noise-Suppression-Auto-Encoder.\n",
    "\n",
    "The original code was very disorganized and included repetitive library imports as well as unclear descriptions for what is occuring. This notebook polishes up the original and include better descriptions for what the author had done to develop their model and what will act as a base model to compare our groups models. \n",
    "\n",
    "Note, the author initially included two models, titled Architecture 1 and Architecture 2. He discarded the first and advises to instead reduce network size and latency. This first Architecture in this case was removed and only the second will be used as a baseline."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dependencies "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-26 18:51:52.191615: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-04-26 18:51:52.860214: I tensorflow/core/platform/cpu_feature_guard.cc:183] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE3 SSE4.1 SSE4.2 AVX, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.12.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "import math\n",
    "from PIL import Image\n",
    "import time\n",
    "import random\n",
    "from scipy.stats import norm\n",
    "\n",
    "%matplotlib inline\n",
    "import IPython.display\n",
    "from ipywidgets import interact, interactive, fixed\n",
    "\n",
    "from scipy.io import wavfile\n",
    "from scipy.signal import butter, lfilter\n",
    "import scipy.ndimage\n",
    "\n",
    "import gzip\n",
    "import copy\n",
    "import os\n",
    "import glob\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import keras\n",
    "from keras.layers import Input,Conv2D,MaxPooling2D,UpSampling2D,concatenate\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.layers import Dropout\n",
    "from keras.models import Model\n",
    "from keras.optimizers import SGD, Adam, RMSprop \n",
    "import keras.layers as layers\n",
    "import keras.models as models\n",
    "from keras.initializers import orthogonal\n",
    "import tensorflow as tf # used to display GPU count\n",
    "from tensorflow import keras\n",
    "from tensorflow.python.keras.saving import saving_utils as _saving_utils\n",
    "from tensorflow.python.framework import convert_to_constants as convert_variables_to_constants_v2\n",
    "\n",
    "print(tf.version.VERSION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  2\n"
     ]
    }
   ],
   "source": [
    "os.environ['TF_FORCE_GPU_ALLOW_GROWTH'] = 'true'\n",
    "\n",
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data\n",
    "\n",
    "Data comes from Kaggel - Libri Speech Noise Dataset (https://www.kaggle.com/datasets/7e537768e8abf483cb224e60d10b73c0e9b8620556c5797556724a27c3f508c4/data).\n",
    "\n",
    "Paths to processed data (.wav to .npy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# paths to processed data \n",
    "path_mat_train = '/data/csc6621/24-team-c/dataset/LibriNoise_Train_Test_NPY/mat_train/'\n",
    "path_mat_test = '/data/csc6621/24-team-c/dataset/LibriNoise_Train_Test_NPY/mat_test/'\n",
    "path_mat_ytrain = '/data/csc6621/24-team-c/dataset/LibriNoise_Train_Test_NPY/mat_ytrain/'\n",
    "path_mat_ytest = '/data/csc6621/24-team-c/dataset/LibriNoise_Train_Test_NPY/mat_ytest/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preparing training data for model input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7000/7000 [00:00<00:00, 1396903.99it/s]\n",
      "100%|██████████| 7000/7000 [00:00<00:00, 511955.36it/s]\n",
      "100%|██████████| 105/105 [00:00<00:00, 782241.42it/s]\n",
      "100%|██████████| 105/105 [00:00<00:00, 850196.76it/s]\n"
     ]
    }
   ],
   "source": [
    "train_image = []\n",
    "path = path_mat_train\n",
    "for filename in tqdm(glob.glob(os.path.join(path, '*.npy'))):\n",
    "    train_image.append(os.path.join(filename))\n",
    "    \n",
    "ytrain_image = []\n",
    "path = path_mat_ytrain\n",
    "for filename in tqdm(glob.glob(os.path.join(path, '*.npy'))):\n",
    "    ytrain_image.append(os.path.join(filename))\n",
    "    \n",
    "test_image = []\n",
    "path = path_mat_test\n",
    "for filename in tqdm(glob.glob(os.path.join(path, '*.npy'))):\n",
    "    test_image.append(os.path.join(filename))\n",
    "    \n",
    "ytest_image = []\n",
    "path = path_mat_ytest\n",
    "for filename in tqdm(glob.glob(os.path.join(path, '*.npy'))):\n",
    "    ytest_image.append(os.path.join(filename))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dimension size of inputted data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(257, 62)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ROW = 257\n",
    "COL = 62\n",
    "\n",
    "INPUT_DIM = (ROW,COL,3)\n",
    "INPUT_DIM[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions\n",
    "\n",
    "Global variables needed for following functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "FFT_LENGTH = 512\n",
    "WINDOW_LENGTH = 512\n",
    "WINDOW_STEP = int(WINDOW_LENGTH / 2)\n",
    "magnitudeMin = float(\"inf\")\n",
    "magnitudeMax = float(\"-inf\")\n",
    "phaseMin = float(\"inf\")\n",
    "phaseMax = float(\"-inf\")\n",
    "\n",
    "phaseMax = 3.141592653589793 \n",
    "phaseMin = -3.141592653589793\n",
    "magnitudeMax = 2211683.973249525\n",
    "magnitudeMin = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def amplifyMagnitudeByLog(d):\n",
    "    \"\"\"\n",
    "    Function takes magnitude value and returns amplified version of it using a log amplification method.\n",
    "    \n",
    "    Paramaters:\n",
    "    -d: magnitude value\n",
    "    \n",
    "    Returns:\n",
    "    - Amplified magnitude value\n",
    "    \n",
    "    \"\"\"\n",
    "    return 188.301 * math.log10(d + 1)\n",
    "\n",
    "def weakenAmplifiedMagnitude(d):\n",
    "    \"\"\"\n",
    "    Function responsible for inversing the amplified magnitude by log value. \n",
    "    \n",
    "    Parameters:\n",
    "    - d: amplified magnitude value\n",
    "    \n",
    "    Returns:\n",
    "    - inversed magnitude value\n",
    "    \"\"\"\n",
    "    \n",
    "    return math.pow(10, d/188.301)-1\n",
    "\n",
    "def generateLinearScale(magnitudePixels, phasePixels, magnitudeMin, magnitudeMax, phaseMin, phaseMax):\n",
    "    \"\"\"\n",
    "    Function generates a linear-scale representation of the spectrogram thats good for visualization. \n",
    "    \n",
    "    Returns:\n",
    "    - spectorgram image\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    height = magnitudePixels.shape[0]\n",
    "    width = magnitudePixels.shape[1]\n",
    "    magnitudeRange = magnitudeMax - magnitudeMin\n",
    "    phaseRange = phaseMax - phaseMin\n",
    "    rgbArray = np.zeros((height, width, 3), 'uint8')\n",
    "    \n",
    "    for w in range(width):\n",
    "        for h in range(height):\n",
    "            magnitudePixels[h,w] = (magnitudePixels[h,w] - magnitudeMin) / (magnitudeRange) * 255 * 2\n",
    "            magnitudePixels[h,w] = amplifyMagnitudeByLog(magnitudePixels[h,w])\n",
    "            phasePixels[h,w] = (phasePixels[h,w] - phaseMin) / (phaseRange) * 255\n",
    "            red = 255 if magnitudePixels[h,w] > 255 else magnitudePixels[h,w]\n",
    "            green = (magnitudePixels[h,w] - 255) if magnitudePixels[h,w] > 255 else 0\n",
    "            blue = phasePixels[h,w]\n",
    "            rgbArray[h,w,0] = int(red)\n",
    "            rgbArray[h,w,1] = int(green)\n",
    "            rgbArray[h,w,2] = int(blue)\n",
    "    return rgbArray\n",
    "\n",
    "def recoverLinearScale(rgbArray, magnitudeMin, magnitudeMax, phaseMin, phaseMax):\n",
    "    \"\"\"\n",
    "    Function is the inverse operation for generate linear scale. Takes a spectrogram array in linear scale and\n",
    "    reconstructs the original magntitude and phase of the array. \n",
    "    \n",
    "    Returns:\n",
    "    - reconstructed magnitude and phase values \n",
    "    \n",
    "    \"\"\"\n",
    "    width = rgbArray.shape[1]\n",
    "    height = rgbArray.shape[0]\n",
    "    magnitudeVals = rgbArray[:,:,0].astype(float) + rgbArray[:,:,1].astype(float)\n",
    "    phaseVals = rgbArray[:,:,2].astype(float)\n",
    "    phaseRange = phaseMax - phaseMin\n",
    "    magnitudeRange = magnitudeMax - magnitudeMin\n",
    "\n",
    "    \n",
    "    for w in range(width):\n",
    "        for h in range(height):\n",
    "            phaseVals[h,w] = (phaseVals[h,w] / 255 * phaseRange) + phaseMin\n",
    "            magnitudeVals[h,w] = weakenAmplifiedMagnitude(magnitudeVals[h,w])\n",
    "            magnitudeVals[h,w] = (magnitudeVals[h,w] / (255*2) * magnitudeRange) + magnitudeMin\n",
    "    return magnitudeVals, phaseVals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recoverSignalFromSpectrogram(numpyarray):\n",
    "    \"\"\"\n",
    "    Function recovers signal from spectrogram.\n",
    "    \n",
    "    Paramaters:\n",
    "    - numpyarray: spectrogram data stored as a NumPy array. \n",
    "    \n",
    "    Return: \n",
    "    - recovered: recovered signal.\n",
    "    \"\"\"\n",
    "\n",
    "    data = np.array(numpyarray, dtype='uint8')\n",
    "    \n",
    "    # get spectogram width and height \n",
    "    width = data.shape[1]\n",
    "    height = data.shape[0]\n",
    "    \n",
    "    # Calling recoverLinearScale to recover magnitude and phase values from normalized spectrogram data\n",
    "    magnitudeVals, phaseVals = recoverLinearScale(data, magnitudeMin, magnitudeMax, phaseMin, phaseMax)\n",
    "    \n",
    "\n",
    "    recovered = np.zeros(WINDOW_LENGTH * width // 2 + WINDOW_STEP, dtype=np.int16)\n",
    "    recovered = np.array(recovered,dtype=np.int16)\n",
    "    \n",
    "    # iterating over each column (width or frequency bin) of the spectrogram\n",
    "    # for each freq bin  it constructs representation of the signal by combining the magnitude & phase \n",
    "    # use inverse FFT to convert constructed representation back to time-domain signal\n",
    "    for w in range(width):\n",
    "        toInverse = np.zeros(height, dtype=np.complex_)\n",
    "        for h in range(height):\n",
    "            magnitude = magnitudeVals[height-h-1,w]\n",
    "            phase = phaseVals[height-h-1,w]\n",
    "            toInverse[h] = magnitude * math.cos(phase) + (1j * magnitude * math.sin(phase))\n",
    "        signal = np.fft.irfft(toInverse)\n",
    "        recovered[w*WINDOW_STEP:w*WINDOW_STEP + WINDOW_LENGTH] += signal[:WINDOW_LENGTH].astype(np.int16)\n",
    "    return recovered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_gen_train(train_batch_size):\n",
    "    while True:\n",
    "        for start in range(0,nb_train_samples,train_batch_size):\n",
    "            x_batch = []\n",
    "            y_batch = []\n",
    "            end = min(start + train_batch_size, nb_train_samples)\n",
    "            for img_path in range(start, end):\n",
    "                img_train = np.load(train_image[img_path])\n",
    "                img_train = img_train/255\n",
    "                x_batch.append(img_train)\n",
    "                img_ytrain = np.load(ytrain_image[img_path])\n",
    "                img_ytrain = img_ytrain/255\n",
    "                y_batch.append(img_ytrain)\n",
    "            yield (np.array(x_batch), np.array(y_batch)) \n",
    "            \n",
    "def data_gen_test(test_batch_size):\n",
    "    while True:\n",
    "        for start in range(0,nb_test_samples,test_batch_size):\n",
    "            x_batch = []\n",
    "            y_batch = []\n",
    "            end = min(start + test_batch_size, nb_test_samples)\n",
    "            for img_path in range(start, end):\n",
    "                img_test = np.load(test_image[img_path])\n",
    "                img_test = img_test/255\n",
    "                x_batch.append(img_test)\n",
    "                img_ytest= np.load(ytest_image[img_path])\n",
    "                img_ytest = img_ytest/255\n",
    "                y_batch.append(img_ytest)\n",
    "            yield (np.array(x_batch), np.array(y_batch)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomCallback(keras.callbacks.Callback):\n",
    "    \"\"\"\n",
    "    Custome callback class that inherits from 'keras.callbacks.Callback' and is responsible for generating predictions for \n",
    "    random test images at the end of each epoch during model training. \n",
    "    \"\"\"\n",
    "    def on_epoch_end(self, autoencoder_train, epoch:int, logs=None)->None:\n",
    "        \"\"\"\n",
    "        Function is called at the end of each epoch. Function is responsible for randomly selecting test image, \n",
    "        preprocessing, and normalizing image [0,1] and dividing by 255 to reshape it. Then model is used to predict the \n",
    "        output and that output is post-processed back to normal scale and then into audio data \n",
    "        (uses recoverSignalFromSpectrogram for that). Then audio is saved as a WAV file. Also, saves current model trained.\n",
    "        \n",
    "        Paramaters:\n",
    "        - autoencoder_train: AE model being trained.\n",
    "        - epochs: current epoch number.\n",
    "        - logs: dict containing training metrics for current epoch; optional.\n",
    "        \n",
    "        \"\"\"\n",
    "        \n",
    "        rate = 16000 # sampling rate \n",
    "        \n",
    "        for j in range(5):\n",
    "            r_num = random.randint(0, nb_test_samples-1)\n",
    "            test_file = test_image[r_num] # randomly selecting test image\n",
    "            img_test = np.load(test_file) \n",
    "            \n",
    "            \n",
    "            img_test = img_test/255 # normalizing \n",
    "            img_test = img_test.reshape(-1, ROW,COL,3) # reshape\n",
    "            \n",
    "            \n",
    "            decoded_imgs = autoencoder.predict(img_test) # predict\n",
    "            \n",
    "            decoded_imgs = decoded_imgs.reshape(ROW,COL,3) # rehsape\n",
    "            decoded_imgs = decoded_imgs*255 # denormalization\n",
    "            decoded_imgs = decoded_imgs.astype(np.int16) \n",
    "            \n",
    "            data = recoverSignalFromSpectrogram(decoded_imgs)\n",
    "            \n",
    "            scipy.io.wavfile.write('./'+\"predict_{}\".format(j)+'.wav', rate, data) # saving random predicted image into audio\n",
    "        \n",
    "        autoencoder.save('model.h5') # save current model iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Conv2DLayer(x, filters, kernel, strides, padding, block_id, kernel_init=orthogonal()):\n",
    "    \"\"\"\n",
    "    Function applies convolution, activation, dropout, and batch normalization sequentially and returns a output tensor.\n",
    "    \n",
    "    Paramaters:\n",
    "    - x: input tensor\n",
    "    - filters: number of filters\n",
    "    - kernel: size of kernel\n",
    "    - strides: stride of convolution\n",
    "    - padding: padding mode\n",
    "    - block_id: identifier of the block\n",
    "    - kernel_init: kernel initializer (default orthogonal)\n",
    "    \n",
    "    \"\"\"\n",
    "    prefix = f'block_{block_id}_'\n",
    "    x = layers.Conv2D(filters, kernel_size=kernel, strides=strides, padding=padding,\n",
    "                      kernel_initializer=kernel_init, name=prefix+'conv')(x)\n",
    "    x = layers.LeakyReLU(name=prefix+'lrelu')(x)\n",
    "    x = layers.Dropout(0.2, name=prefix+'drop')((x))\n",
    "    x = layers.BatchNormalization(name=prefix+'conv_bn')(x)\n",
    "    return x\n",
    "\n",
    "def Transpose_Conv2D(x, filters, kernel, strides, padding, block_id, kernel_init=orthogonal()):\n",
    "    \"\"\"\n",
    "    Function is opposite of Conv2DLayer, it transposes convolutional layers.\n",
    "    \n",
    "    \"\"\"\n",
    "    prefix = f'block_{block_id}_'\n",
    "    x = layers.Conv2DTranspose(filters, kernel_size=kernel, strides=strides, padding=padding,\n",
    "                               kernel_initializer=kernel_init, name=prefix+'de-conv')(x)\n",
    "    x = layers.LeakyReLU(name=prefix+'lrelu')(x)\n",
    "    x = layers.Dropout(0.2, name=prefix+'drop')((x))\n",
    "    x = layers.BatchNormalization(name=prefix+'conv_bn')(x)\n",
    "    return x\n",
    "\n",
    "\n",
    "def AutoEncdoer(input_shape):\n",
    "    \"\"\"\n",
    "    Function defines AE architecture. \n",
    "    \n",
    "    \"\"\"\n",
    "    inputs = layers.Input(shape=input_shape)\n",
    "    \n",
    "    # 256 x 256\n",
    "    conv1 = Conv2DLayer(inputs, 64, 3, strides=1, padding='same', block_id=1)\n",
    "    conv2 = Conv2DLayer(conv1, 64, 3, strides=1, padding='same', block_id=2)\n",
    "    \n",
    "    # 128 x 128\n",
    "    conv3 = Conv2DLayer(conv2, 128, 5, strides=1, padding='same', block_id=3)\n",
    "    \n",
    "    # 64 x 64\n",
    "    conv4 = Conv2DLayer(conv3, 128, 3, strides=1, padding='same', block_id=4)\n",
    "    conv5 = Conv2DLayer(conv4, 256, 5, strides=1, padding='same', block_id=5)\n",
    "    \n",
    "    # 32 x 32\n",
    "    conv6 = Conv2DLayer(conv5, 512, 3, strides=1, padding='same', block_id=6)\n",
    "    \n",
    "    # 16 x 16\n",
    "    deconv1 = Transpose_Conv2D(conv6, 512, 3, strides=1, padding='same', block_id=7)\n",
    "    \n",
    "    # 32 x 32\n",
    "    skip1 = layers.concatenate([deconv1, conv5], name='skip1')\n",
    "    conv7 = Conv2DLayer(skip1, 256, 3, strides=1, padding='same', block_id=8)\n",
    "    deconv2 = Transpose_Conv2D(conv7, 128, 3, strides=1, padding='same', block_id=9)\n",
    "    \n",
    "    # 64 x 64\n",
    "    skip2 = layers.concatenate([deconv2, conv3], name='skip2')\n",
    "    conv8 = Conv2DLayer(skip2, 128, 5, strides=1, padding='same', block_id=10)\n",
    "    deconv3 = Transpose_Conv2D(conv8, 64, 3, strides=1, padding='same', block_id=11)\n",
    "    \n",
    "    # 128 x 128\n",
    "    skip3 = layers.concatenate([deconv3, conv2], name='skip3')\n",
    "    conv9 = Conv2DLayer(skip3, 64, 5, strides=1, padding='same', block_id=12)\n",
    "    deconv4 = Transpose_Conv2D(conv9, 64, 3, strides=1, padding='same', block_id=13)\n",
    "    \n",
    "    # 256 x 256\n",
    "    skip3 = layers.concatenate([deconv4, conv1])\n",
    "    conv10 = layers.Conv2D(3, 3, strides=1, padding='same', activation='sigmoid',\n",
    "                       kernel_initializer=orthogonal(), name='final_conv')(skip3)\n",
    "\n",
    "    \n",
    "    return models.Model(inputs=inputs, outputs=conv10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Base Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_train_samples = 7000 # sample of converted .wav files \n",
    "nb_test_samples = 105\n",
    "\n",
    "train_batch_size = [5,4,3,2]\n",
    "test_batch_size = [5,4,3,2]\n",
    "\n",
    "epochs = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-26 18:51:57.310762: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:47] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
      "2024-04-26 18:51:57.310810: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1638] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13797 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:61:00.0, compute capability: 7.5\n",
      "2024-04-26 18:51:57.313762: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:47] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
      "2024-04-26 18:51:57.313791: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1638] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 13797 MB memory:  -> device: 1, name: Tesla T4, pci bus id: 0000:da:00.0, compute capability: 7.5\n"
     ]
    }
   ],
   "source": [
    "opt = Adam(lr=0.001)\n",
    "autoencoder = AutoEncdoer((ROW,COL, 3))\n",
    "autoencoder.compile(optimizer=opt, loss=['mae','mse'], metrics=['mse','accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 257, 62, 3)  0           []                               \n",
      "                                ]                                                                 \n",
      "                                                                                                  \n",
      " block_1_conv (Conv2D)          (None, 257, 62, 64)  1792        ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " block_1_lrelu (LeakyReLU)      (None, 257, 62, 64)  0           ['block_1_conv[0][0]']           \n",
      "                                                                                                  \n",
      " block_1_drop (Dropout)         (None, 257, 62, 64)  0           ['block_1_lrelu[0][0]']          \n",
      "                                                                                                  \n",
      " block_1_conv_bn (BatchNormaliz  (None, 257, 62, 64)  256        ['block_1_drop[0][0]']           \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " block_2_conv (Conv2D)          (None, 257, 62, 64)  36928       ['block_1_conv_bn[0][0]']        \n",
      "                                                                                                  \n",
      " block_2_lrelu (LeakyReLU)      (None, 257, 62, 64)  0           ['block_2_conv[0][0]']           \n",
      "                                                                                                  \n",
      " block_2_drop (Dropout)         (None, 257, 62, 64)  0           ['block_2_lrelu[0][0]']          \n",
      "                                                                                                  \n",
      " block_2_conv_bn (BatchNormaliz  (None, 257, 62, 64)  256        ['block_2_drop[0][0]']           \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " block_3_conv (Conv2D)          (None, 257, 62, 128  204928      ['block_2_conv_bn[0][0]']        \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " block_3_lrelu (LeakyReLU)      (None, 257, 62, 128  0           ['block_3_conv[0][0]']           \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " block_3_drop (Dropout)         (None, 257, 62, 128  0           ['block_3_lrelu[0][0]']          \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " block_3_conv_bn (BatchNormaliz  (None, 257, 62, 128  512        ['block_3_drop[0][0]']           \n",
      " ation)                         )                                                                 \n",
      "                                                                                                  \n",
      " block_4_conv (Conv2D)          (None, 257, 62, 128  147584      ['block_3_conv_bn[0][0]']        \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " block_4_lrelu (LeakyReLU)      (None, 257, 62, 128  0           ['block_4_conv[0][0]']           \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " block_4_drop (Dropout)         (None, 257, 62, 128  0           ['block_4_lrelu[0][0]']          \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " block_4_conv_bn (BatchNormaliz  (None, 257, 62, 128  512        ['block_4_drop[0][0]']           \n",
      " ation)                         )                                                                 \n",
      "                                                                                                  \n",
      " block_5_conv (Conv2D)          (None, 257, 62, 256  819456      ['block_4_conv_bn[0][0]']        \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " block_5_lrelu (LeakyReLU)      (None, 257, 62, 256  0           ['block_5_conv[0][0]']           \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " block_5_drop (Dropout)         (None, 257, 62, 256  0           ['block_5_lrelu[0][0]']          \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " block_5_conv_bn (BatchNormaliz  (None, 257, 62, 256  1024       ['block_5_drop[0][0]']           \n",
      " ation)                         )                                                                 \n",
      "                                                                                                  \n",
      " block_6_conv (Conv2D)          (None, 257, 62, 512  1180160     ['block_5_conv_bn[0][0]']        \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " block_6_lrelu (LeakyReLU)      (None, 257, 62, 512  0           ['block_6_conv[0][0]']           \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " block_6_drop (Dropout)         (None, 257, 62, 512  0           ['block_6_lrelu[0][0]']          \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " block_6_conv_bn (BatchNormaliz  (None, 257, 62, 512  2048       ['block_6_drop[0][0]']           \n",
      " ation)                         )                                                                 \n",
      "                                                                                                  \n",
      " block_7_de-conv (Conv2DTranspo  (None, 257, 62, 512  2359808    ['block_6_conv_bn[0][0]']        \n",
      " se)                            )                                                                 \n",
      "                                                                                                  \n",
      " block_7_lrelu (LeakyReLU)      (None, 257, 62, 512  0           ['block_7_de-conv[0][0]']        \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " block_7_drop (Dropout)         (None, 257, 62, 512  0           ['block_7_lrelu[0][0]']          \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " block_7_conv_bn (BatchNormaliz  (None, 257, 62, 512  2048       ['block_7_drop[0][0]']           \n",
      " ation)                         )                                                                 \n",
      "                                                                                                  \n",
      " skip1 (Concatenate)            (None, 257, 62, 768  0           ['block_7_conv_bn[0][0]',        \n",
      "                                )                                 'block_5_conv_bn[0][0]']        \n",
      "                                                                                                  \n",
      " block_8_conv (Conv2D)          (None, 257, 62, 256  1769728     ['skip1[0][0]']                  \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " block_8_lrelu (LeakyReLU)      (None, 257, 62, 256  0           ['block_8_conv[0][0]']           \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " block_8_drop (Dropout)         (None, 257, 62, 256  0           ['block_8_lrelu[0][0]']          \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " block_8_conv_bn (BatchNormaliz  (None, 257, 62, 256  1024       ['block_8_drop[0][0]']           \n",
      " ation)                         )                                                                 \n",
      "                                                                                                  \n",
      " block_9_de-conv (Conv2DTranspo  (None, 257, 62, 128  295040     ['block_8_conv_bn[0][0]']        \n",
      " se)                            )                                                                 \n",
      "                                                                                                  \n",
      " block_9_lrelu (LeakyReLU)      (None, 257, 62, 128  0           ['block_9_de-conv[0][0]']        \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " block_9_drop (Dropout)         (None, 257, 62, 128  0           ['block_9_lrelu[0][0]']          \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " block_9_conv_bn (BatchNormaliz  (None, 257, 62, 128  512        ['block_9_drop[0][0]']           \n",
      " ation)                         )                                                                 \n",
      "                                                                                                  \n",
      " skip2 (Concatenate)            (None, 257, 62, 256  0           ['block_9_conv_bn[0][0]',        \n",
      "                                )                                 'block_3_conv_bn[0][0]']        \n",
      "                                                                                                  \n",
      " block_10_conv (Conv2D)         (None, 257, 62, 128  819328      ['skip2[0][0]']                  \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " block_10_lrelu (LeakyReLU)     (None, 257, 62, 128  0           ['block_10_conv[0][0]']          \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " block_10_drop (Dropout)        (None, 257, 62, 128  0           ['block_10_lrelu[0][0]']         \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " block_10_conv_bn (BatchNormali  (None, 257, 62, 128  512        ['block_10_drop[0][0]']          \n",
      " zation)                        )                                                                 \n",
      "                                                                                                  \n",
      " block_11_de-conv (Conv2DTransp  (None, 257, 62, 64)  73792      ['block_10_conv_bn[0][0]']       \n",
      " ose)                                                                                             \n",
      "                                                                                                  \n",
      " block_11_lrelu (LeakyReLU)     (None, 257, 62, 64)  0           ['block_11_de-conv[0][0]']       \n",
      "                                                                                                  \n",
      " block_11_drop (Dropout)        (None, 257, 62, 64)  0           ['block_11_lrelu[0][0]']         \n",
      "                                                                                                  \n",
      " block_11_conv_bn (BatchNormali  (None, 257, 62, 64)  256        ['block_11_drop[0][0]']          \n",
      " zation)                                                                                          \n",
      "                                                                                                  \n",
      " skip3 (Concatenate)            (None, 257, 62, 128  0           ['block_11_conv_bn[0][0]',       \n",
      "                                )                                 'block_2_conv_bn[0][0]']        \n",
      "                                                                                                  \n",
      " block_12_conv (Conv2D)         (None, 257, 62, 64)  204864      ['skip3[0][0]']                  \n",
      "                                                                                                  \n",
      " block_12_lrelu (LeakyReLU)     (None, 257, 62, 64)  0           ['block_12_conv[0][0]']          \n",
      "                                                                                                  \n",
      " block_12_drop (Dropout)        (None, 257, 62, 64)  0           ['block_12_lrelu[0][0]']         \n",
      "                                                                                                  \n",
      " block_12_conv_bn (BatchNormali  (None, 257, 62, 64)  256        ['block_12_drop[0][0]']          \n",
      " zation)                                                                                          \n",
      "                                                                                                  \n",
      " block_13_de-conv (Conv2DTransp  (None, 257, 62, 64)  36928      ['block_12_conv_bn[0][0]']       \n",
      " ose)                                                                                             \n",
      "                                                                                                  \n",
      " block_13_lrelu (LeakyReLU)     (None, 257, 62, 64)  0           ['block_13_de-conv[0][0]']       \n",
      "                                                                                                  \n",
      " block_13_drop (Dropout)        (None, 257, 62, 64)  0           ['block_13_lrelu[0][0]']         \n",
      "                                                                                                  \n",
      " block_13_conv_bn (BatchNormali  (None, 257, 62, 64)  256        ['block_13_drop[0][0]']          \n",
      " zation)                                                                                          \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 257, 62, 128  0           ['block_13_conv_bn[0][0]',       \n",
      "                                )                                 'block_1_conv_bn[0][0]']        \n",
      "                                                                                                  \n",
      " final_conv (Conv2D)            (None, 257, 62, 3)   3459        ['concatenate[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 7,963,267\n",
      "Trainable params: 7,958,531\n",
      "Non-trainable params: 4,736\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "autoencoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ncp_callback = tf.keras.callbacks.ModelCheckpoint(\\n    filepath=checkpoint_path, \\n    verbose=1, \\n    save_weights_only=True,\\n    period=PERIOD\\n'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PERIOD = 5\n",
    "\n",
    "# Include the epoch in the file name (uses `str.format`)\n",
    "checkpoint_path = \"modelcheckpoints/cp-{epoch:04d}.ckpt\"\n",
    "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
    "\n",
    "# Create a callback that saves the model's weights every 10 epochs\n",
    "\"\"\"\n",
    "cp_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_path, \n",
    "    verbose=1, \n",
    "    save_weights_only=True,\n",
    "    period=PERIOD\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the weights using the `checkpoint_path` format\n",
    "autoencoder.save_weights(checkpoint_path.format(epoch=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'modelcheckpoints/cp-0000.ckpt'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "latest = tf.train.latest_checkpoint(checkpoint_dir)\n",
    "latest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'modelcheckpoints'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.checkpoint.checkpoint.CheckpointLoadStatus at 0x7fce2c11f460>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the previously saved weights\n",
    "autoencoder.load_weights(latest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-26 18:51:59.871828: I tensorflow/core/common_runtime/executor.cc:1209] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "2024-04-26 18:52:01.343678: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:1014] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape inmodel/block_1_drop/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n",
      "2024-04-26 18:52:01.701007: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:424] Loaded cuDNN version 8901\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(train_batch_size)):\n",
    "    autoencoder_train = autoencoder.fit(data_gen_train(train_batch_size[i]),\n",
    "                                    epochs= epochs,\n",
    "                                    verbose=1,\n",
    "                                    steps_per_epoch= nb_train_samples // train_batch_size[i],\n",
    "                                    validation_data= data_gen_test(test_batch_size[i]),\n",
    "                                    validation_steps=nb_test_samples // test_batch_size[i],\n",
    "                                    callbacks=[CustomCallback()])\n",
    "    plt.subplot(211)\n",
    "    plt.title('Loss')\n",
    "    plt.plot(autoencoder_train.history['loss'], label='train')\n",
    "    plt.plot(autoencoder_train.history['val_loss'], label='test')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    plt.subplot(212)\n",
    "    plt.title('Mean Squared Error')\n",
    "    plt.plot(autoencoder_train.history['mean_squared_error'], label='train')\n",
    "    plt.plot(autoencoder_train.history['val_mean_squared_error'], label='test')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    # list all data in history\n",
    "    print(autoencoder_train.history.keys())\n",
    "    # summarize history for accuracy\n",
    "    plt.plot(autoencoder_train.history['accuracy'])\n",
    "    plt.plot(autoencoder_train.history['val_accuracy'])\n",
    "    plt.title('model accuracy')\n",
    "    plt.ylabel('accuracy')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'test'], loc='upper left')\n",
    "    plt.show()\n",
    "#     # summarize history for loss\n",
    "#     plt.plot(autoencoder_train.history['loss'])\n",
    "#     plt.plot(autoencoder_train.history['val_loss'])\n",
    "#     plt.title('model loss')\n",
    "#     plt.ylabel('loss')\n",
    "#     plt.xlabel('epoch')\n",
    "#     plt.legend(['train', 'test'], loc='upper left')\n",
    "#     plt.show()\n",
    "\n",
    "# evaluate the model=\n",
    "#     _, train_acc = autoencoder.evaluate(data_gen_train(train_batch_size[i]), verbose=0)\n",
    "#     _, test_acc = autoencoder.evaluate(data_gen_test(test_batch_size[i]), verbose=0)\n",
    "#     print('Train: %.3f, Test: %.3f' % (train_acc, test_acc))\n",
    "# plot training history\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
